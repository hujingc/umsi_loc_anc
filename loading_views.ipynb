{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "external-ocean",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "excessive-apple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fuzzywuzzy\n",
      "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "removed-builder",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jingcong\\miniconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Setup\n",
    "# installs and imports\n",
    "#!pip install couchdb\n",
    "#!pip install pandas\n",
    "import couchdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "warnings.filterwarnings(\"ignore\") # for replace remove string part in _id\n",
    "\n",
    "# flatten json\n",
    "import json \n",
    "import pandas as pd \n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "# Read Access Credentials\n",
    "with open(\"passwords.csv\") as myfile:\n",
    "    head = [next(myfile) for x in range(1)]\n",
    "info = str(head[0]).split(',')\n",
    "name = info[0]\n",
    "pw = info[1]\n",
    "\n",
    "# Connect to Server\n",
    "secure_remote_server = couchdb.Server('https://'+name+':'+pw+'@couchdb3.prtd.app/')\n",
    "db = secure_remote_server['anc5']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-desktop",
   "metadata": {},
   "source": [
    "## Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "positive-auckland",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'db' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Extract data USE LIMITS UNTIL IT WORKS DO NOT INCLUDE DOCS\n",
    "#rows = db.view('umsi/clone_pca_analyses', limit=10)\n",
    "rows = db.view('pca/query-analyses') # _id column is same as analysis id\n",
    "data = [row['value'] for row in rows]\n",
    "analyses = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pursuant-symphony",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'analyses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-5e3086241f89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sampleId:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manalyses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampleId\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'analyses:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manalyses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'objectId:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manalyses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjectId\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'analyses' is not defined"
     ]
    }
   ],
   "source": [
    "print('sampleId:', len(analyses.sampleId.unique()))\n",
    "print('analyses:', len(analyses))\n",
    "print('objectId:', len(analyses.objectId.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-phrase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace [] and {} with NaN\n",
    "analyses.deltaE = analyses.deltaE.apply(lambda y: np.nan if y==[] else y)\n",
    "analyses.col = analyses.col.apply(lambda y: np.nan if y=={} else y)\n",
    "analyses.fors = analyses.fors.apply(lambda y: np.nan if y==[] else y)\n",
    "analyses.ftir = analyses.ftir.apply(lambda y: np.nan if y==[] else y)\n",
    "analyses.tensile = analyses.tensile.apply(lambda y: np.nan if y=={} else y)\n",
    "analyses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out data\n",
    "fors_data = analyses[analyses['type']=='fors'].dropna(axis=1, how='all').reset_index().drop(['index'], axis=1)\n",
    "ftir_data = analyses[analyses['type']=='ftir'].dropna(axis=1, how='all').reset_index().drop(['index'], axis=1)\n",
    "tensile_data = analyses[analyses['type']=='tensile'].dropna(axis=1, how='all').reset_index().drop(['index'], axis=1)\n",
    "ph_data = analyses[analyses['type']=='ph'].dropna(axis=1, how='all').reset_index().drop(['index'], axis=1)\n",
    "sec_data = analyses[analyses['type']=='sec'].dropna(axis=1, how='all').reset_index().drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-picking",
   "metadata": {},
   "source": [
    "### FORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-coupon",
   "metadata": {},
   "outputs": [],
   "source": [
    "fors_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-group",
   "metadata": {},
   "source": [
    "### FTIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftir_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-palestinian",
   "metadata": {},
   "source": [
    "### TENSILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-vessel",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensile_frame = pd.concat(tensile_data['tensile'].apply(lambda x:json_normalize(x)).values.tolist()).reset_index().drop(['index'], axis=1)\n",
    "tensile=pd.concat([tensile_data, tensile_frame], axis=1)\n",
    "tensile.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-sterling",
   "metadata": {},
   "source": [
    "### PH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-grave",
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-institution",
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_data.astype({'ph': 'float'}).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-chile",
   "metadata": {},
   "source": [
    "### SEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-cisco",
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_frame = pd.concat(sec_data['sec'].apply(lambda x:json_normalize(x)).values.tolist()).reset_index().drop(['index'], axis=1)\n",
    "sec=pd.concat([sec_data, sec_frame], axis=1)\n",
    "sec.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-coating",
   "metadata": {},
   "source": [
    "## Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-printer",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Extract data USE LIMITS UNTIL IT WORKS DO NOT INCLUDE DOCS\n",
    "#rows = db.view('umsi/clone_pca_analyses', limit=10)\n",
    "rows = db.view('pca/query-books') # _id column is same as analysis id\n",
    "data = [row['value'] for row in rows]\n",
    "books = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-southeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "books.doubleFold = books.doubleFold.apply(lambda y: np.nan if y=='' else y)\n",
    "books=books.astype({'doubleFold': 'float'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-virus",
   "metadata": {},
   "outputs": [],
   "source": [
    "books.publisher = books.publisher.apply(lambda y: np.nan if y=='' else y)\n",
    "books=books.astype({'publisher': 'str'})\n",
    "books.publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-modeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-company",
   "metadata": {},
   "source": [
    "## Combine Data Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-liquid",
   "metadata": {},
   "source": [
    "### 1. Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-begin",
   "metadata": {},
   "source": [
    "#### TENSILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns that we don't need\n",
    "tensile_cleaned = tensile.drop(columns =['_id', 'analysisId', 'type', 'tensile'])\n",
    "\n",
    "#rename id columns\n",
    "tensile_cleaned.rename(columns ={'objectId':'book_id', 'sampleId':'sample_id'}, inplace = True)\n",
    "\n",
    "#change book id into string\n",
    "tensile_cleaned['book_id'] = tensile_cleaned['book_id'].astype(str)\n",
    "\n",
    "tensile_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-purple",
   "metadata": {},
   "source": [
    "#### PH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-action",
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_data_cleaned = ph_data.drop(columns =['_id', 'objectId', 'analysisId', 'type'])\n",
    "ph_data_cleaned.rename(columns ={'sampleId':'sample_id'}, inplace = True)\n",
    "ph_data_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-rough",
   "metadata": {},
   "source": [
    "#### SEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_cleaned = sec.drop(columns =['_id', 'objectId','analysisId', 'sec', 'type'])\n",
    "sec_cleaned.rename(columns ={'sampleId':'sample_id'}, inplace = True)\n",
    "sec_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-samuel",
   "metadata": {},
   "source": [
    "#### DOUBLEFOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOT IMPORTANT\n",
    "# doublefold_cleaned = books[['id', 'doubleFold']]\n",
    "# doublefold_cleaned.rename(columns={'id':'book_id'}, inplace=True)\n",
    "# doublefold_cleaned['book_id'] = doublefold_cleaned['book_id'].astype(str)\n",
    "# doublefold_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-hours",
   "metadata": {},
   "source": [
    "#### PUBLISHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "publisher_cleaned = books[['id', 'publisher']]\n",
    "publisher_cleaned.rename(columns={'id':'book_id'}, inplace=True)\n",
    "publisher_cleaned['book_id'] = publisher_cleaned['book_id'].astype(str)\n",
    "publisher_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-debate",
   "metadata": {},
   "source": [
    "### 2. Combine Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-senate",
   "metadata": {},
   "source": [
    "#### Combine all Analysis dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-agency",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine tensile, ph, and sec analyses data frames\n",
    "analyses_combined = tensile_cleaned.merge(ph_data_cleaned,on='sample_id').merge(sec_cleaned,on='sample_id')\n",
    "\n",
    "#drop id columns\n",
    "numeric_data = analyses_combined.drop(columns=['book_id','sample_id'])\n",
    "\n",
    "#turn all data into floats\n",
    "numeric_data = numeric_data.astype(float)\n",
    "\n",
    "numeric_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-medicaid",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export data as csv\n",
    "pca_csv_data = numeric_data.to_csv('numeric_data_for_pca.csv', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-aspect",
   "metadata": {},
   "source": [
    "#### Combine Analysis and Publisher Data for Publisher Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-blank",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyses_combined = analyses_combined.astype(float)\n",
    "# analyses_combined['book_id'] = analyses_combined['book_id'].astype(str)\n",
    "\n",
    "#combine analysis and publisher data\n",
    "all_combined = analyses_combined.merge(publisher_cleaned, on='book_id', how='left')\n",
    "\n",
    "#drop id columns\n",
    "publisher_analysis_data = all_combined.drop(columns=['book_id','sample_id'])\n",
    "\n",
    "#transform data (excluding publisher) to numeric values\n",
    "cols = ['maxLoad','stressMaxLoad','strainMaxLoad','energyAbsorp','youngsMod','ph','sec_Mn','sec_Mw','sec_polyDisp','sec_calcMass','sec_massRec']\n",
    "publisher_analysis_data[cols] = publisher_analysis_data[cols].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "\n",
    "\n",
    "#fuzzy matching code based on code from https://pythoninoffice.com/use-fuzzy-string-matching-in-pandas/\n",
    "df1 = pd.read_csv('publisher_list.csv') #This is the correct, cleaned list of publishers\n",
    "df2 = publisher_analysis_data #This is our dataframe with chemical data & the uncleaned publishers (different spellings, etc.)\n",
    "\n",
    "#df1df2['publisher_from_df1'] values look like (Publisher name from df1, fuzzy score)\n",
    "df2['publisher_from_df1'] = df2['publisher'].apply(lambda x: process.extractOne(x, df1['Publisher'].to_list(),score_cutoff=80))\n",
    "\n",
    "#remove score from list\n",
    "publisher_from_df1_list = df2['publisher_from_df1'].to_list()\n",
    "publisher_from_df1_list = [_[0] if _ != None else None for _ in publisher_from_df1_list]\n",
    "df2['publisher_from_df1'] = publisher_from_df1_list\n",
    "\n",
    "#drop and rename columns, change publisher type to string\n",
    "df2.drop(['publisher'],axis=1, inplace=True)\n",
    "df2.rename(columns={'publisher_from_df1':'publisher'}, inplace=True)\n",
    "df2['publisher'] = df2['publisher'].astype(str)\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "publisher_analysis_data = df2.to_csv('publisher_analysis_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-camcorder",
   "metadata": {},
   "source": [
    "### 3. Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-strap",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-jamaica",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-liabilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "sns.heatmap(numeric_data.corr(), annot=True)\n",
    "# fix for mpl bug that cuts off top/bottom of seaborn viz\n",
    "b, t = plt.ylim() # discover the values for bottom and top\n",
    "b += 0.5 # Add 0.5 to the bottom\n",
    "t -= 0.5 # Subtract 0.5 from the top\n",
    "plt.ylim(b, t) # update the ylim(bottom, top) values\n",
    "plt.show() # ta-da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-canyon",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(numeric_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-vaccine",
   "metadata": {},
   "source": [
    "#### Publisher Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "publisher_analysis_data = pd.read_csv('publisher_analysis_data.csv')\n",
    "publisher_analysis_data.drop(columns={'Unnamed: 0'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-novelty",
   "metadata": {},
   "outputs": [],
   "source": [
    "publisher_analysis_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-hours",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a table for the averages per publisher\n",
    "publisher_averages = publisher_analysis_data.groupby('publisher').mean()\n",
    "publisher_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(30,8))\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, horizontalalignment='right')\n",
    "sns.boxplot(x=\"publisher\",y=\"ph\", data=publisher_analysis_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_lm = ols('ph ~ publisher', data=publisher_analysis_data).fit()\n",
    "table = sm.stats.anova_lm(ph_lm, typ=2) # Type 2 ANOVA DataFrame\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = pairwise_tukeyhsd(publisher_analysis_data['ph'], publisher_analysis_data['publisher'])\n",
    "res2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-batch",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
