{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install couchdb\n",
    "#!pip install pandas\n",
    "#!pip install matplotlib\n",
    "#!pip install seaborn\n",
    "#import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-opposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Setup\n",
    "# # installs and imports\n",
    "# #!pip install couchdb\n",
    "# #!pip install pandas\n",
    "# import couchdb\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\") # for replace remove string part in _id\n",
    "\n",
    "# # flatten json\n",
    "# import json \n",
    "# import pandas as pd \n",
    "# from pandas.io.json import json_normalize\n",
    "\n",
    "# # Read Access Credentials\n",
    "# with open(\"passwords.csv\") as myfile:\n",
    "#     head = [next(myfile) for x in range(1)]\n",
    "# info = str(head[0]).split(',')\n",
    "# name = info[0]\n",
    "# pw = info[1]\n",
    "\n",
    "# # Connect to Server\n",
    "# secure_remote_server = couchdb.Server('https://'+name+':'+pw+'@couchdb3.prtd.app/')\n",
    "# db = secure_remote_server['anc5']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-fireplace",
   "metadata": {},
   "source": [
    "### Old code based on extracting everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Extract data (will take 5-10 minutes, recommend putting these lines in a separate cell)\n",
    "# rows = db.view('_all_docs', include_docs=True, limit=1000) # ,limit=10\n",
    "# data = [row['doc'] for row in rows]\n",
    "# df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-variation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Separate out data types\n",
    "# analysis = df[df['_id'].str.contains(\"analysis\")].reset_index()\n",
    "# book = df[df['_id'].str.contains(\"book\")].reset_index() #DONE\n",
    "# sample = df[df['_id'].str.contains(\"sample\")].reset_index() #DONE\n",
    "# institution = df[df['_id'].str.contains(\"institution\")].reset_index() #IGNORE\n",
    "# person = df[df['_id'].str.contains(\"person\")].reset_index() #IGNORE\n",
    "# paper = df[df['_id'].str.contains(\"paper\")].reset_index() #IGNORE\n",
    "# catalog = df[df['_id'].str.contains(\"catalog\")].reset_index() #IGNORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data: Sample\n",
    "\n",
    "# def checkSitu(x,key):\n",
    "#     try:\n",
    "#         return x[key]\n",
    "#     except:\n",
    "#         return np.NaN\n",
    "    \n",
    "# # Initial Setup\n",
    "# sample1 = sample.dropna(axis=1, how='all').drop('index', axis=1)\n",
    "# sample1['_id'] = sample1['_id'].str.replace('sample:','')\n",
    "\n",
    "# # Relabel columns\n",
    "# sample1.rename(columns={\"_id\": \"sample_id\"}, inplace=True)\n",
    "# sample1['objectId'] = sample1['objectId'].str.replace('book:','')\n",
    "# sample1.rename(columns={\"objectId\": \"book_id\"}, inplace=True)\n",
    "\n",
    "# #Separate out columns\n",
    "# sample2 = sample1[['sample_id','book_id', 'barcode', 'procedure', 'notes', 'inSitu', 'pageSampled']]\n",
    "\n",
    "# # Extract inSitu information\n",
    "# sample2['status']=sample2['inSitu'].apply(lambda x: checkSitu(x,'isInSitu'))\n",
    "# sample2['type']=sample2['inSitu'].apply(lambda x: checkSitu(x,'type'))\n",
    "# sample2['location']=sample2['inSitu'].apply(lambda x: checkSitu(x,'location'))\n",
    "# sample2['set']=sample2['inSitu'].apply(lambda x: checkSitu(x,'set'))\n",
    "\n",
    "# #sample2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-commercial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data: Book\n",
    "\n",
    "# %%time\n",
    "# # https://www.kaggle.com/jboysen/quick-tutorial-flatten-nested-json-in-pandas\n",
    "\n",
    "# book1 = book.dropna(axis=1, how='all').drop('index', axis=1)\n",
    "\n",
    "# # rename columns\n",
    "# book1.rename(columns={\"_id\": \"book_id\",\"institutionId\":\"institution_id\",\"catalogId\":\"catalog_id\"}, inplace=True)\n",
    "\n",
    "# # clean id column content\n",
    "# book1['book_id'] = book1['book_id'].str.replace('book:','') #WARNING line\n",
    "# book1['institution_id'] = book1['institution_id'].str.replace('institution:','')\n",
    "# book1['catalog_id'] = book1['catalog_id'].str.replace('catalog:','')\n",
    "\n",
    "# # separate out columns\n",
    "# book2 = book1[['book_id','catalog_id', 'institution_id', 'catalog', 'description', 'batch', 'doubleFold', 'condition']]\n",
    "\n",
    "# # flatten and concatenate\n",
    "# book2['doubleFold'] = book2['doubleFold'].apply(lambda x:x['value'])\n",
    "# catalog_frame = pd.concat(book2['catalog'].apply(lambda x:json_normalize(x)).values.tolist()).reset_index().drop(['index'], axis=1)\n",
    "# description_frame = pd.concat(book2['description'].apply(lambda x:json_normalize(x)).values.tolist()).reset_index().drop(['index'], axis=1)\n",
    "# condition_frame = pd.concat(book2['condition'].apply(lambda x:json_normalize(x)).values.tolist()).reset_index().drop(['index'], axis=1)\n",
    "\n",
    "# book3 = pd.concat([book2, catalog_frame, description_frame, condition_frame], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-attitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis1 = analysis.dropna(axis=1, how='all').drop('index', axis=1)\n",
    "# analysis1['_id'] = analysis1['_id'].str.replace('analysis:','')\n",
    "# analysis1\n",
    "# data column is a list(dict(['type'-->dv1, 'src'-->dict(header, createdon, filename), 'spectrum'-->dict(values,labels)]))\n",
    "# analysis_data = analysis1[['_id','data']]\n",
    "# analysis_data['data_len']= 1\n",
    "# analysis_data['data']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
